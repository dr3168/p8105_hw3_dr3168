---
title: "p8105_hw3_dr3168"
author: "Daniela Rochez"
date: "10/14/2021"
output: github_document
editor_options: 
  chunk_output_type: console
---
```{r}
library(tidyverse)
library(p8105.datasets)
library(forcats)
library(patchwork)
library(skimr)
data("instacart")
str(instacart)

skim(instacart)
#There are 1, 384, 617 observations with 15 variables. Some of these variables include order IDs, product IDs, and name of products.  
```

Counting amount of aisles
```{r}
instacart %>% 
  count(aisle)
#There are 134 aisles.
```

Finding most popular aisles
```{r}
instacart %>% 
  count(aisle) %>% 
    filter(min_rank(desc(n)) < 4)

#The top three aisles with the most purchases is fresh fruits, fresh vegetables, and packaged vegetables and fruits.
```

Making a plot for the number of orders in each aisle
```{r}
instacart %>% 
  count(aisle) %>% 
    rename(number_of_purchases=n) %>% 
      filter(number_of_purchases>10000) %>% 
       mutate(aisle=fct_reorder(aisle, 
                               number_of_purchases ))%>% 
          ggplot(aes(x = aisle, y = number_of_purchases ))+
            geom_point()+
              coord_flip()
```

Making a table for popular products in certain aisles
```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", 
          "dog food care", "packaged vegetables fruits")) %>%
    group_by(aisle,product_name) %>% 
     summarize(n_obs = n()) %>% 
      filter(min_rank(desc(n_obs)) < 4) %>% 
       knitr::kable(digits = 1)

#The most popular products in the baking ingredients is cane sugar, light brown sugar, and baking soda. The most popular products in the dog food care aisle is organix Chicken & Brown Rice Recipe , small dog biscuits, and Snack Sticks Chicken & Rice Recipe Dog Treats. The most popular products in packaged vegetables fruits is organic baby spinach, organic blueberries, and organic raspberries.
```

Making Pink Lady Apples and Coffee Ice Cream table
```{r}
instacart %>% 
  filter(product_name %in% 
           c("Pink Lady Apples", "Coffee Ice Cream"))%>%
    group_by(product_name, order_dow) %>% 
      summarize(mean_orders=mean(order_hour_of_day)) %>%
          mutate(order_dow= recode(order_dow,`0`="Sunday",
                `1`="Monday",`2`="Tuesday",`3`="Wednesday",
                `4`="Thursday",`5`="Friday",
                `6`="Saturday"))%>% 
             pivot_wider(names_from =product_name,
                         values_from = mean_orders) %>%
                knitr::kable(digits = 1)

#It seems like the mean hours for the Pink Lady Apples and the Coffee Ice Cream ranges from 11 am 3 pm throughout the week.
```

Loading BRFSS Data
```{r}
data("brfss_smart2010")
str(brfss_smart2010)
```

Cleaning BRFSS Data and Releveling
```{r}
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic=="Overall Health") %>% 
  mutate(response =fct_relevel(response,c("Poor", "Fair",
                                          "Good", "Very good",
                                          "Excellent")))
```

States observed at more than 7 locations in 2002
```{r}
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
    filter(year==2002 & topic =="Overall Health") %>% 
      group_by(locationabbr) %>% 
        distinct(locationdesc) %>% 
          summarise(n_obs=n())%>% 
            filter(n_obs >=7)

#The states that were observed at 7 or more locations in 2002 were Connecticut, Florida, Massachusetts, North Carolina, New Jersey, and Pennsylvania.
```

#States observed at more than 7 locations in 2010
```{r}
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
    filter(year==2010 & topic =="Overall Health") %>% 
      group_by(locationabbr) %>% 
        distinct(locationdesc) %>% 
          summarise(n_obs=n())%>% 
            filter(n_obs >=7)

#The states that were observed at 7 or more locations in 2010 were California, Colorado, Florida, Massachusetts,Maryland, North Carolina,New England, New Jersey,New York, Ohio, Pennsylvania South Carolina, Texas, and Washington.

```

Spaghetti plot with excellent variable
```{r}
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
    filter(response== "Excellent" & 
           topic =="Overall Health") %>%
      group_by(year, locationabbr) %>% 
         summarize(average_data_value= 
                     mean(data_value, na.rm=T)) %>% 
            ggplot(aes(x = year, y = average_data_value,
                       color=locationabbr)) + 
                  geom_line()
#The average data values fluctuates between each state. However most of the values fall between 17.5 and 27.5.
```

Making Two panel plot
```{r}
data_value_2006= 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(year==2006 & topic =="Overall Health") %>%
  filter(locationabbr=="NY") %>% 
  mutate(response =fct_relevel(response,c("Poor", "Fair", "Good", 
                                          "Very good", "Excellent")))%>%
  ggplot(aes(x = response, y = data_value)) + 
  geom_point(aes(color = locationdesc)) +
  theme(legend.position = "none")+
  ggtitle("2006 Data")+
   coord_flip()

data_value_2010= 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(year==2010 & topic =="Overall Health") %>%
  filter(locationabbr=="NY") %>% 
  mutate(response =fct_relevel(response,c("Poor", "Fair", "Good", 
                                          "Very good", "Excellent")))%>%
  ggplot(aes(x = response, y = data_value)) + 
  geom_point(aes(color = locationdesc)) +
  theme(legend.position = "bottom")+
  ggtitle("2010 Data")+
   coord_flip()

data_value_2006+data_value_2010

#The data values also vary between NY county and and response type. It seems like for both years, data value starts to increase as response variables start to get better. The only exception is for the "excellent" response variable. The data values decreases slightly for that variable.

```

Loading accelerometer data
```{r}
accel_data= read_csv("~/School/FALL 2021/P8105/p8105_hw3_dr3168/accel_data.csv")
summarise(accel_data)
accel_data
```

Tidying the data and naming variables
```{r}
accel_tidy_data= 
  pivot_longer(
    accel_data, 
    activity.1:activity.1440,
    names_to = "activity_minute",
    names_prefix = "activity.",
    values_to = "activity_count") %>% 
  mutate(day =fct_relevel(day,c("Monday", "Tuesday", "Wednesday",
                                  "Thursday", "Friday", "Saturday",
                                  "Sunday"))) %>% 
  mutate(weekday_or_weekend= recode(day, `Monday`= "Weekday",
                                      `Tuesday`="Weekday",
                                      `Wednesday`="Weekday",
                                      `Thursday`="Weekday",
                                      `Friday`="Weekday",
                                      `Saturday`= "Weekend",
                                      `Sunday`="Weekend")) %>% 
  mutate(activity_minute=as.numeric(activity_minute))
  
accel_tidy_data

#There are 50,400 observations and 6 variables. These variables include the week, day of each week, each activity minute and the count per activity minute.
  
```

Making Total activity variable
```{r}
accel_total_activity=
  accel_tidy_data %>% 
  group_by(day_id) %>% 
  mutate(total_activity= sum(activity_count)) %>% 
  pivot_wider(
    names_from =activity_minute,
    values_from = activity_count) %>% 
  knitr::kable(digits = 1)

  
```

Making a single panel plot
```{r}
accel_total_activity %>% 
  ggplot(aes(x = activity_minute, y = activity_count,group=day_id, color=day)) + 
  geom_line(alpha=0.2)+
  geom_smooth(aes(group=day), se=F)
  
```


```{r}
#Did I do this right?

#X should be minutes and group by day_id

#There is an overall decrease in total activity count on the weekends compare to the week days. However, throughout the week,the activity count fluctuates.
```

